{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports + Path Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from torch import optim\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile2vec_dir = '/home/agupta21/gcloud/231n_gitproject'\n",
    "sys.path.append('../')\n",
    "sys.path.append(tile2vec_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import TileTripletsDataset, GetBands, RandomFlipAndRotate, ClipAndScale, ToFloatTensor, triplet_dataloader\n",
    "from src.tilenet import make_tilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training import prep_triplets, train_triplet_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "from src.resnet import ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classification\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader + TileNet Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Environment stuff\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Parameters\n",
    "img_type = 'naip'\n",
    "tile_dir = '/home/agupta21/gcloud/231n_gitproject/data/triplets/'\n",
    "bands = 4\n",
    "augment = False\n",
    "batch_size = 50\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "n_triplets = 108700 #modification: adding 8700 more for semi-supervised learning purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader set up complete.\n"
     ]
    }
   ],
   "source": [
    "dataloader = triplet_dataloader(img_type, tile_dir, bands=bands, augment=augment,\n",
    "                                batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, \n",
    "                                n_triplets=n_triplets, pairs_only=True)\n",
    "print('Dataloader set up complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = bands\n",
    "z_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TileNet set up complete.\n"
     ]
    }
   ],
   "source": [
    "TileNet = make_tilenet(in_channels=in_channels, z_dim=z_dim, strat2=False)\n",
    "TileNet.train()\n",
    "if cuda: TileNet.cuda()\n",
    "print('TileNet set up complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter \n",
    "lr = 0.0003 #hyper tuned\n",
    "optimizer = optim.Adam(TileNet.parameters(), lr=lr, betas=(0.9, 0.999)) #hyper tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model + Writing Each Epoch to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "margin = 10\n",
    "l2 = 0.01\n",
    "print_every = 10000\n",
    "save_models = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/home/agupta21/gcloud/231n_gitproject/models/'\n",
    "if not os.path.exists(model_dir): os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.................\n",
      "Epoch 1: [10000/108700 (9%)], Avg loss: 6.0657\n",
      "Epoch 1: [20000/108700 (18%)], Avg loss: 5.3830\n",
      "Epoch 1: [30000/108700 (28%)], Avg loss: 5.0873\n",
      "Epoch 1: [50000/108700 (46%)], Avg loss: 4.9285\n",
      "Epoch 1: [60000/108700 (55%)], Avg loss: 4.7964\n",
      "Epoch 1: [70000/108700 (64%)], Avg loss: 4.8594\n",
      "Epoch 1: [80000/108700 (74%)], Avg loss: 4.6677\n",
      "Epoch 1: [90000/108700 (83%)], Avg loss: 4.7307\n",
      "Epoch 1: [100000/108700 (92%)], Avg loss: 4.6602\n",
      "Epoch 2: [10000/108700 (9%)], Avg loss: 4.6709\n",
      "Epoch 2: [20000/108700 (18%)], Avg loss: 4.6138\n",
      "Epoch 2: [30000/108700 (28%)], Avg loss: 4.5226\n",
      "Epoch 2: [40000/108700 (37%)], Avg loss: 4.5351\n",
      "Epoch 2: [50000/108700 (46%)], Avg loss: 4.5406\n",
      "Epoch 2: [60000/108700 (55%)], Avg loss: 4.5161\n",
      "Epoch 2: [70000/108700 (64%)], Avg loss: 4.4106\n",
      "Epoch 2: [80000/108700 (74%)], Avg loss: 4.4889\n",
      "Epoch 2: [90000/108700 (83%)], Avg loss: 4.4245\n",
      "Epoch 2: [100000/108700 (92%)], Avg loss: 4.4215\n",
      "Finished epoch 2: 5658.949s\n",
      "  Average loss: 4.5061\n",
      "  Average l_n: 3.9917\n",
      "  Average l_d: -13.3472\n",
      "  Average l_nd: -9.3555\n",
      "\n",
      "Epoch 3: [10000/108700 (9%)], Avg loss: 4.4184\n",
      "Epoch 3: [20000/108700 (18%)], Avg loss: 4.3356\n",
      "Epoch 3: [30000/108700 (28%)], Avg loss: 4.3402\n",
      "Epoch 3: [40000/108700 (37%)], Avg loss: 4.3351\n",
      "Epoch 3: [50000/108700 (46%)], Avg loss: 4.2527\n",
      "Epoch 3: [60000/108700 (55%)], Avg loss: 4.3568\n",
      "Epoch 3: [70000/108700 (64%)], Avg loss: 4.1873\n",
      "Epoch 3: [80000/108700 (74%)], Avg loss: 4.2603\n",
      "Epoch 3: [90000/108700 (83%)], Avg loss: 4.2663\n",
      "Epoch 3: [100000/108700 (92%)], Avg loss: 4.2672\n",
      "Finished epoch 3: 8480.482s\n",
      "  Average loss: 4.2960\n",
      "  Average l_n: 3.7924\n",
      "  Average l_d: -13.2546\n",
      "  Average l_nd: -9.4622\n",
      "\n",
      "Epoch 4: [10000/108700 (9%)], Avg loss: 4.1862\n",
      "Epoch 4: [20000/108700 (18%)], Avg loss: 4.2318\n",
      "Epoch 4: [30000/108700 (28%)], Avg loss: 4.1843\n",
      "Epoch 4: [40000/108700 (37%)], Avg loss: 4.1513\n",
      "Epoch 4: [50000/108700 (46%)], Avg loss: 4.2747\n",
      "Epoch 4: [60000/108700 (55%)], Avg loss: 4.1700\n",
      "Epoch 4: [70000/108700 (64%)], Avg loss: 4.0977\n",
      "Epoch 4: [80000/108700 (74%)], Avg loss: 4.1372\n",
      "Epoch 4: [90000/108700 (83%)], Avg loss: 4.1463\n",
      "Epoch 4: [100000/108700 (92%)], Avg loss: 4.0992\n",
      "Finished epoch 4: 11289.975s\n",
      "  Average loss: 4.1648\n",
      "  Average l_n: 3.6505\n",
      "  Average l_d: -13.1768\n",
      "  Average l_nd: -9.5264\n",
      "\n",
      "Epoch 5: [10000/108700 (9%)], Avg loss: 4.1135\n",
      "Epoch 5: [20000/108700 (18%)], Avg loss: 4.0818\n",
      "Epoch 5: [30000/108700 (28%)], Avg loss: 4.0379\n",
      "Epoch 5: [40000/108700 (37%)], Avg loss: 4.0470\n",
      "Epoch 5: [50000/108700 (46%)], Avg loss: 4.1520\n",
      "Epoch 5: [60000/108700 (55%)], Avg loss: 4.1179\n",
      "Epoch 5: [70000/108700 (64%)], Avg loss: 4.1169\n",
      "Epoch 5: [80000/108700 (74%)], Avg loss: 4.0407\n",
      "Epoch 5: [90000/108700 (83%)], Avg loss: 4.0694\n",
      "Epoch 5: [100000/108700 (92%)], Avg loss: 4.1348\n",
      "Finished epoch 5: 14099.898s\n",
      "  Average loss: 4.0908\n",
      "  Average l_n: 3.5749\n",
      "  Average l_d: -13.1287\n",
      "  Average l_nd: -9.5537\n",
      "\n",
      "Epoch 6: [10000/108700 (9%)], Avg loss: 4.0336\n",
      "Epoch 6: [20000/108700 (18%)], Avg loss: 4.0275\n",
      "Epoch 6: [30000/108700 (28%)], Avg loss: 4.0320\n",
      "Epoch 6: [40000/108700 (37%)], Avg loss: 4.0531\n",
      "Epoch 6: [50000/108700 (46%)], Avg loss: 4.0640\n",
      "Epoch 6: [60000/108700 (55%)], Avg loss: 4.0118\n",
      "Epoch 6: [70000/108700 (64%)], Avg loss: 3.9986\n",
      "Epoch 6: [80000/108700 (74%)], Avg loss: 3.9505\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "#with open(results_fn, 'w') as file:\n",
    "\n",
    "plot_list = []\n",
    "print('Begin training.................')\n",
    "for epoch in range(0, epochs):\n",
    "    (avg_loss, bullshit, avg_l_n, avg_l_d, avg_l_nd) = train_triplet_epoch(\n",
    "        TileNet, cuda, dataloader, optimizer, epoch+1, margin=margin, l2=l2,\n",
    "        print_every=print_every, t0=t0)\n",
    "    plot_list.append((epoch+1,avg_loss))\n",
    "    append_name = \"strat1ht1_ep\" + str(epoch+1) + \".ckpt\"\n",
    "    if save_models:\n",
    "        model_fn = os.path.join(model_dir,append_name)\n",
    "        torch.save(TileNet.state_dict(),model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plot_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Process Y Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note to self: need to embed tiles first and then figure out loop for reading in the saved model and plotting\n",
    "#the classification accuracies per epoch\n",
    "tile_dir = '../data/tiles'\n",
    "n_tiles = 1000\n",
    "y = np.load(os.path.join(tile_dir, 'y.npy'))\n",
    "print(y.shape)\n",
    "#print(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CDL classes\n",
    "print(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = LabelEncoder().fit_transform(y)\n",
    "print(set(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Epochs' Weights + Run each on tile embeddings + Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up model\n",
    "in_channels = 4\n",
    "z_dim = 512\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTileEmbeddings(tilenet):\n",
    "    X = np.zeros((n_tiles, z_dim))\n",
    "    for idx in range(n_tiles):\n",
    "        tile = np.load(os.path.join(tile_dir, '{}tile.npy'.format(idx+1)))\n",
    "        # Get first 4 NAIP channels (5th is CDL mask)\n",
    "        tile = tile[:,:,:4]\n",
    "        # Rearrange to PyTorch order\n",
    "        tile = np.moveaxis(tile, -1, 0)\n",
    "        tile = np.expand_dims(tile, axis=0)\n",
    "        # Scale to [0, 1]\n",
    "        tile = tile / 255\n",
    "        # Embed tile\n",
    "        tile = torch.from_numpy(tile).float()\n",
    "        tile = Variable(tile)\n",
    "        if cuda: tile = tile.cuda()\n",
    "        z = tilenet.encode(tile)\n",
    "        if cuda: z = z.cpu()\n",
    "        z = z.data.numpy() #1 by 512\n",
    "        X[idx,:] = z\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochsToAccuracy = []\n",
    "epochsToSTD = []\n",
    "for i in range(0,epochs): #iterator\n",
    "    curEpoch = i + 1\n",
    "    # Setting up model\n",
    "    tilenet = ResNet18()\n",
    "    if cuda: tilenet.cuda()\n",
    "    model_fn = \"../models/strat1ht1_ep\"+str(curEpoch)+\".ckpt\" #open file\n",
    "    #checkpoint = torch.load(model_fn)\n",
    "    tilenet.load_state_dict(torch.load(model_fn), strict=False)\n",
    "    #tilenet.load_state_dict(checkpoint)\n",
    "    tilenet.eval()\n",
    "    \n",
    "    X = getTileEmbeddings(tilenet) #function above\n",
    "    \n",
    "    #train random forest classifier\n",
    "    n_trials = 100\n",
    "    accs = np.zeros((n_trials,))\n",
    "    for i in range(n_trials):\n",
    "        # Splitting data and training RF classifer\n",
    "        X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2)\n",
    "        rf = RandomForestClassifier(n_estimators=100)\n",
    "        rf.fit(X_tr, y_tr) #X-tr is 512 by 1\n",
    "        accs[i] = rf.score(X_te, y_te)\n",
    "    print(\"Results for Epoch Number: \", str(curEpoch))\n",
    "    print('Mean accuracy: {:0.4f}'.format(accs.mean()))\n",
    "    print('Standard deviation: {:0.4f}'.format(accs.std()))\n",
    "    epochsToAccuracy.append((curEpoch,accs.mean()))\n",
    "    epochsToSTD.append((curEpoch,accs.std()))\n",
    "print(epochsToAccuracy)\n",
    "print(epochsToSTD)\n",
    "    #save value\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epochsToSTD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(*zip(*epochsToAccuracy))\n",
    "plt.title('Triplet Augmentation Average Test Performance')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "print(epochsToAccuracy[9][1], \"was the Max Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(*zip(*plot_list))\n",
    "plt.title('Triplet Augmentation Loss Performance')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "print(\"The min loss was\",str(plot_list[9][1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(*zip(*epochsToSTD))\n",
    "plt.title('STD on Random Forest Test Prediction')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Standard Deviation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
