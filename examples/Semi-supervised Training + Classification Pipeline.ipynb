{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports + Path Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from torch import optim\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile2vec_dir = '/home/agupta21/gcloud/231n_gitproject'\n",
    "sys.path.append('../')\n",
    "sys.path.append(tile2vec_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import TileTripletsDataset, GetBands, RandomFlipAndRotate, ClipAndScale, ToFloatTensor, triplet_dataloader\n",
    "from src.tilenet import make_tilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training import prep_triplets, train_triplet_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "from src.resnet import ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classification\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader + TileNet Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Environment stuff\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Parameters\n",
    "img_type = 'naip'\n",
    "tile_dir = '/home/agupta21/gcloud/231n_gitproject/data/triplets/'\n",
    "bands = 4\n",
    "augment = False\n",
    "batch_size = 50\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "n_triplets = 108700 #modification: adding 8700 more for semi-supervised learning purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader set up complete.\n"
     ]
    }
   ],
   "source": [
    "dataloader = triplet_dataloader(img_type, tile_dir, bands=bands, augment=augment,\n",
    "                                batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, \n",
    "                                n_triplets=n_triplets, pairs_only=True)\n",
    "print('Dataloader set up complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = bands\n",
    "z_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TileNet set up complete.\n"
     ]
    }
   ],
   "source": [
    "TileNet = make_tilenet(in_channels=in_channels, z_dim=z_dim)\n",
    "TileNet.train()\n",
    "if cuda: TileNet.cuda()\n",
    "print('TileNet set up complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter \n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(TileNet.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model + Writing Each Epoch to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "margin = 10\n",
    "l2 = 0.01\n",
    "print_every = 10000\n",
    "save_models = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/home/agupta21/gcloud/231n_gitproject/models/'\n",
    "if not os.path.exists(model_dir): os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.................\n",
      "Epoch 1: [10000/108700 (9%)], Avg loss: 6.4529\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-421b2b317372>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     (avg_loss, avg_l_n, avg_l_d, avg_l_nd) = train_triplet_epoch(\n\u001b[1;32m      8\u001b[0m         \u001b[0mTileNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         print_every=print_every, t0=t0)\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mplot_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mappend_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test1_ep\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".ckpt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gcloud/231n_gitproject/src/training.py\u001b[0m in \u001b[0;36mtrain_triplet_epoch\u001b[0;34m(model, cuda, dataloader, optimizer, epoch, margin, l2, print_every, t0)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0msum_l_n\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0msum_l_d\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "#with open(results_fn, 'w') as file:\n",
    "\n",
    "plot_list = []\n",
    "print('Begin training.................')\n",
    "for epoch in range(0, epochs):\n",
    "    (avg_loss, avg_l_n, avg_l_d, avg_l_nd) = train_triplet_epoch(\n",
    "        TileNet, cuda, dataloader, optimizer, epoch+1, margin=margin, l2=l2,\n",
    "        print_every=print_every, t0=t0)\n",
    "    plot_list.append((epoch+1,avg_loss))\n",
    "    append_name = \"test1_ep\" + str(epoch+1) + \".ckpt\"\n",
    "    if save_models:\n",
    "        model_fn = os.path.join(model_dir,append_name)\n",
    "        torch.save(TileNet.state_dict(),model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plot_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Process Y Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note to self: need to embed tiles first and then figure out loop for reading in the saved model and plotting\n",
    "#the classification accuracies per epoch\n",
    "tile_dir = '../data/tiles'\n",
    "n_tiles = 1000\n",
    "y = np.load(os.path.join(tile_dir, 'y.npy'))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CDL classes\n",
    "print(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = LabelEncoder().fit_transform(y)\n",
    "print(set(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Epochs' Weights + Run each on tile embeddings + Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up model\n",
    "in_channels = 4\n",
    "z_dim = 512\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTileEmbeddings(tilenet):\n",
    "    X = np.zeros((n_tiles, z_dim))\n",
    "    for idx in range(n_tiles):\n",
    "        tile = np.load(os.path.join(tile_dir, '{}tile.npy'.format(idx+1)))\n",
    "        # Get first 4 NAIP channels (5th is CDL mask)\n",
    "        tile = tile[:,:,:4]\n",
    "        # Rearrange to PyTorch order\n",
    "        tile = np.moveaxis(tile, -1, 0)\n",
    "        tile = np.expand_dims(tile, axis=0)\n",
    "        # Scale to [0, 1]\n",
    "        tile = tile / 255\n",
    "        # Embed tile\n",
    "        tile = torch.from_numpy(tile).float()\n",
    "        tile = Variable(tile)\n",
    "        if cuda: tile = tile.cuda()\n",
    "        z = tilenet.encode(tile)\n",
    "        if cuda: z = z.cpu()\n",
    "        z = z.data.numpy() #1 by 512\n",
    "        X[idx,:] = z\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochsToAccuracy = []\n",
    "epochsToSTD = []\n",
    "for i in range(0,epochs): #iterator\n",
    "    curEpoch = i + 1\n",
    "    # Setting up model\n",
    "    tilenet = ResNet18()\n",
    "    if cuda: tilenet.cuda()\n",
    "    model_fn = \"../models/test1_ep\"+str(curEpoch)+\".ckpt\" #open file\n",
    "    #checkpoint = torch.load(model_fn)\n",
    "    tilenet.load_state_dict(torch.load(model_fn), strict=False)\n",
    "    #tilenet.load_state_dict(checkpoint)\n",
    "    tilenet.eval()\n",
    "    \n",
    "    X = getTileEmbeddings(tilenet) #function above\n",
    "    \n",
    "    #train random forest classifier\n",
    "    n_trials = 100\n",
    "    accs = np.zeros((n_trials,))\n",
    "    for i in range(n_trials):\n",
    "        # Splitting data and training RF classifer\n",
    "        X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2)\n",
    "        rf = RandomForestClassifier()\n",
    "        rf.fit(X_tr, y_tr) #X-tr is 512 by 1\n",
    "        accs[i] = rf.score(X_te, y_te)\n",
    "    print(\"Results for Epoch Number: \", str(curEpoch))\n",
    "    print('Mean accuracy: {:0.4f}'.format(accs.mean()))\n",
    "    print('Standard deviation: {:0.4f}'.format(accs.std()))\n",
    "    epochsToAccuracy.append((curEpoch,accs.mean()))\n",
    "    epochsToSTD.append((curEpoch,accs.std()))\n",
    "print(epochsToAccuracy)\n",
    "print(epochsToSTD)\n",
    "    #save value\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
